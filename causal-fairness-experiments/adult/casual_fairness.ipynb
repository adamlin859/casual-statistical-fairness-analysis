{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h5kGVUDlzWkj"
      },
      "outputs": [],
      "source": [
        "!pip install 'aif360[all]'  "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cp adult* /usr/local/lib/python3.8/dist-packages/aif360/data/raw/adult/."
      ],
      "metadata": {
        "id": "ViN_6JIYztW7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M9Vde_VB3PhC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "Ih3X_j4n0bez"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "# Load all necessary packages\n",
        "import sys\n",
        "sys.path.append(\"../\")\n",
        "from aif360.datasets import BinaryLabelDataset\n",
        "from aif360.datasets import AdultDataset, GermanDataset, CompasDataset\n",
        "from aif360.metrics import BinaryLabelDatasetMetric\n",
        "from aif360.metrics import ClassificationMetric\n",
        "from aif360.metrics.utils import compute_boolean_conditioning_vector\n",
        "\n",
        "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions import load_preproc_data_adult, load_preproc_data_compas, load_preproc_data_german\n",
        "\n",
        "from aif360.algorithms.inprocessing.adversarial_debiasing import AdversarialDebiasing\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler, MaxAbsScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from IPython.display import Markdown, display\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_eager_execution()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from aif360.datasets import AdultDataset, GermanDataset, CompasDataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def load_preproc_data_adult(protected_attributes=None, sub_samp=False, balance=False):\n",
        "    def custom_preprocessing(df):\n",
        "        \"\"\"The custom pre-processing function is adapted from\n",
        "            https://github.com/fair-preprocessing/nips2017/blob/master/Adult/code/Generate_Adult_Data.ipynb\n",
        "            If sub_samp != False, then return smaller version of dataset truncated to tiny_test data points.\n",
        "        \"\"\"\n",
        "\n",
        "        # Group age by decade\n",
        "        df['Age (decade)'] = df['age'].apply(lambda x: x//10*10)\n",
        "        # df['Age (decade)'] = df['age'].apply(lambda x: np.floor(x/10.0)*10.0)\n",
        "\n",
        "        def group_edu(x):\n",
        "            if x <= 5:\n",
        "                return '<6'\n",
        "            elif x >= 13:\n",
        "                return '>12'\n",
        "            else:\n",
        "                return x\n",
        "\n",
        "        def age_cut(x):\n",
        "            if x >= 70:\n",
        "                return '>=70'\n",
        "            else:\n",
        "                return x\n",
        "\n",
        "        def group_race(x):\n",
        "            if x == \"White\":\n",
        "                return 1.0\n",
        "            else:\n",
        "                return 0.0\n",
        "\n",
        "        # Cluster education and age attributes.\n",
        "        # Limit education range\n",
        "        df['Education Years'] = df['education-num'].apply(lambda x: group_edu(x))\n",
        "        df['Education Years'] = df['Education Years'].astype('category')\n",
        "\n",
        "        # Limit age range\n",
        "        df['Age (decade)'] = df['Age (decade)'].apply(lambda x: age_cut(x))\n",
        "\n",
        "        # Rename income variable\n",
        "        df['Income Binary'] = df['income-per-year']\n",
        "        df['Income Binary'] = df['Income Binary'].replace(to_replace='>50K.', value='>50K', regex=True)\n",
        "        df['Income Binary'] = df['Income Binary'].replace(to_replace='<=50K.', value='<=50K', regex=True)\n",
        "\n",
        "        # Recode sex and race\n",
        "        df['sex'] = df['sex'].replace({'Female': 0.0, 'Male': 1.0})\n",
        "        df['race'] = df['race'].apply(lambda x: group_race(x))\n",
        "\n",
        "        if sub_samp and not balance:\n",
        "            df = df.sample(sub_samp)\n",
        "        if sub_samp and balance:\n",
        "            df_0 = df[df['Income Binary'] == '<=50K']\n",
        "            df_1 = df[df['Income Binary'] == '>50K']\n",
        "            df_0 = df_0.sample(int(sub_samp/2))\n",
        "            df_1 = df_1.sample(int(sub_samp/2))\n",
        "            df = pd.concat([df_0, df_1])\n",
        "        return df\n",
        "\n",
        "    XD_features = ['Age (decade)', 'Education Years', 'hours-per-week', 'sex', 'race']\n",
        "    D_features = ['sex', 'race'] if protected_attributes is None else protected_attributes\n",
        "    Y_features = ['Income Binary']\n",
        "    X_features = list(set(XD_features)-set(D_features))\n",
        "    categorical_features = ['Age (decade)', 'Education Years', 'marital-status', 'workclass']\n",
        "\n",
        "    # privileged classes\n",
        "    all_privileged_classes = {\"sex\": [1.0],\n",
        "                              \"race\": [1.0]}\n",
        "\n",
        "    # protected attribute maps\n",
        "    all_protected_attribute_maps = {\"sex\": {1.0: 'Male', 0.0: 'Female'},\n",
        "                                    \"race\": {1.0: 'White', 0.0: 'Non-white'}}\n",
        "\n",
        "    return AdultDataset(\n",
        "        label_name=Y_features[0],\n",
        "        favorable_classes=['>50K', '>50K.'],\n",
        "        protected_attribute_names=D_features,\n",
        "        privileged_classes=[all_privileged_classes[x] for x in D_features],\n",
        "        instance_weights_name=None,\n",
        "        categorical_features=categorical_features,\n",
        "        features_to_keep=X_features+Y_features+D_features,\n",
        "        na_values=['?'],\n",
        "        metadata={'label_maps': [{1.0: '>50K', 0.0: '<=50K'}],\n",
        "                  'protected_attribute_maps': [all_protected_attribute_maps[x]\n",
        "                                for x in D_features]},\n",
        "        custom_preprocessing=custom_preprocessing)"
      ],
      "metadata": {
        "id": "B4d48Hs_3QAV"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the dataset and split into train and test\n",
        "dataset_orig = load_preproc_data_adult()\n",
        "\n",
        "privileged_groups = [{'sex': 1}]\n",
        "unprivileged_groups = [{'sex': 0}]\n",
        "\n",
        "dataset_orig_train, dataset_orig_test = dataset_orig.split([0.7], shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXTGLTOgy3dV",
        "outputId": "d00aaa2a-4619-446b-dc92-667b4715be22"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Missing Data: 2799 rows removed from AdultDataset.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print out some labels, names, etc.\n",
        "display(Markdown(\"#### Training Dataset shape\"))\n",
        "print(dataset_orig_train.features.shape)\n",
        "display(Markdown(\"#### Favorable and unfavorable labels\"))\n",
        "print(dataset_orig_train.favorable_label, dataset_orig_train.unfavorable_label)\n",
        "display(Markdown(\"#### Protected attribute names\"))\n",
        "print(dataset_orig_train.protected_attribute_names)\n",
        "display(Markdown(\"#### Privileged and unprivileged protected attribute values\"))\n",
        "print(dataset_orig_train.privileged_protected_attributes, \n",
        "      dataset_orig_train.unprivileged_protected_attributes)\n",
        "display(Markdown(\"#### Dataset feature names\"))\n",
        "print(dataset_orig_train.feature_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "ZTniBGWsz5sN",
        "outputId": "86b0a0f7-596e-4728-a7ff-360f089f0820"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "#### Training Dataset shape"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32230, 34)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "#### Favorable and unfavorable labels"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0 0.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "#### Protected attribute names"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['sex', 'race']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "#### Privileged and unprivileged protected attribute values"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([1.]), array([1.])] [array([0.]), array([0.])]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "#### Dataset feature names"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['race', 'sex', 'hours-per-week', 'workclass=Federal-gov', 'workclass=Local-gov', 'workclass=Never-worked', 'workclass=Private', 'workclass=Self-emp-inc', 'workclass=Self-emp-not-inc', 'workclass=State-gov', 'workclass=Without-pay', 'marital-status=Divorced', 'marital-status=Married-AF-spouse', 'marital-status=Married-civ-spouse', 'marital-status=Married-spouse-absent', 'marital-status=Never-married', 'marital-status=Separated', 'marital-status=Widowed', 'Age (decade)=10', 'Age (decade)=20', 'Age (decade)=30', 'Age (decade)=40', 'Age (decade)=50', 'Age (decade)=60', 'Age (decade)=>=70', 'Education Years=6', 'Education Years=7', 'Education Years=8', 'Education Years=9', 'Education Years=10', 'Education Years=11', 'Education Years=12', 'Education Years=<6', 'Education Years=>12']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "min_max_scaler = MaxAbsScaler()\n",
        "dataset_orig_train.features = min_max_scaler.fit_transform(dataset_orig_train.features)\n",
        "dataset_orig_test.features = min_max_scaler.transform(dataset_orig_test.features)\n",
        "metric_scaled_train = BinaryLabelDatasetMetric(dataset_orig_train, \n",
        "                             unprivileged_groups=unprivileged_groups,\n",
        "                             privileged_groups=privileged_groups)\n",
        "display(Markdown(\"#### Scaled dataset - Verify that the scaling does not affect the group label statistics\"))\n",
        "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_scaled_train.mean_difference())\n",
        "metric_scaled_test = BinaryLabelDatasetMetric(dataset_orig_test, \n",
        "                             unprivileged_groups=unprivileged_groups,\n",
        "                             privileged_groups=privileged_groups)\n",
        "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_scaled_test.mean_difference())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "t1ihRF660BXl",
        "outputId": "6a61afa4-1818-4539-b11b-787c2f76a672"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "#### Scaled dataset - Verify that the scaling does not affect the group label statistics"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.196872\n",
            "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.204047\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load post-processing algorithm that equalizes the odds\n",
        "# Learn parameters with debias set to False\n",
        "sess = tf.Session()\n",
        "plain_model = AdversarialDebiasing(privileged_groups = privileged_groups,\n",
        "                          unprivileged_groups = unprivileged_groups,\n",
        "                          scope_name='plain_classifier',\n",
        "                          debias=False,\n",
        "                          sess=sess)"
      ],
      "metadata": {
        "id": "tR_ROaTg0dmw"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plain_model.fit(dataset_orig_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRnDUn4-1wJD",
        "outputId": "120402b9-1377-4d06-89ac-bb8e625e3288"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0; iter: 0; batch classifier loss: 0.625385\n",
            "epoch 0; iter: 200; batch classifier loss: 0.467040\n",
            "epoch 1; iter: 0; batch classifier loss: 0.542668\n",
            "epoch 1; iter: 200; batch classifier loss: 0.375726\n",
            "epoch 2; iter: 0; batch classifier loss: 0.423701\n",
            "epoch 2; iter: 200; batch classifier loss: 0.352262\n",
            "epoch 3; iter: 0; batch classifier loss: 0.310063\n",
            "epoch 3; iter: 200; batch classifier loss: 0.379533\n",
            "epoch 4; iter: 0; batch classifier loss: 0.359917\n",
            "epoch 4; iter: 200; batch classifier loss: 0.411400\n",
            "epoch 5; iter: 0; batch classifier loss: 0.390554\n",
            "epoch 5; iter: 200; batch classifier loss: 0.345831\n",
            "epoch 6; iter: 0; batch classifier loss: 0.331389\n",
            "epoch 6; iter: 200; batch classifier loss: 0.356091\n",
            "epoch 7; iter: 0; batch classifier loss: 0.374946\n",
            "epoch 7; iter: 200; batch classifier loss: 0.445629\n",
            "epoch 8; iter: 0; batch classifier loss: 0.425091\n",
            "epoch 8; iter: 200; batch classifier loss: 0.327098\n",
            "epoch 9; iter: 0; batch classifier loss: 0.356803\n",
            "epoch 9; iter: 200; batch classifier loss: 0.438259\n",
            "epoch 10; iter: 0; batch classifier loss: 0.356109\n",
            "epoch 10; iter: 200; batch classifier loss: 0.245946\n",
            "epoch 11; iter: 0; batch classifier loss: 0.334559\n",
            "epoch 11; iter: 200; batch classifier loss: 0.345710\n",
            "epoch 12; iter: 0; batch classifier loss: 0.357044\n",
            "epoch 12; iter: 200; batch classifier loss: 0.323333\n",
            "epoch 13; iter: 0; batch classifier loss: 0.359739\n",
            "epoch 13; iter: 200; batch classifier loss: 0.312240\n",
            "epoch 14; iter: 0; batch classifier loss: 0.313014\n",
            "epoch 14; iter: 200; batch classifier loss: 0.426233\n",
            "epoch 15; iter: 0; batch classifier loss: 0.307991\n",
            "epoch 15; iter: 200; batch classifier loss: 0.347627\n",
            "epoch 16; iter: 0; batch classifier loss: 0.348843\n",
            "epoch 16; iter: 200; batch classifier loss: 0.337847\n",
            "epoch 17; iter: 0; batch classifier loss: 0.320814\n",
            "epoch 17; iter: 200; batch classifier loss: 0.358732\n",
            "epoch 18; iter: 0; batch classifier loss: 0.298260\n",
            "epoch 18; iter: 200; batch classifier loss: 0.389493\n",
            "epoch 19; iter: 0; batch classifier loss: 0.358577\n",
            "epoch 19; iter: 200; batch classifier loss: 0.284732\n",
            "epoch 20; iter: 0; batch classifier loss: 0.298889\n",
            "epoch 20; iter: 200; batch classifier loss: 0.380119\n",
            "epoch 21; iter: 0; batch classifier loss: 0.330213\n",
            "epoch 21; iter: 200; batch classifier loss: 0.345193\n",
            "epoch 22; iter: 0; batch classifier loss: 0.320048\n",
            "epoch 22; iter: 200; batch classifier loss: 0.293695\n",
            "epoch 23; iter: 0; batch classifier loss: 0.361537\n",
            "epoch 23; iter: 200; batch classifier loss: 0.355386\n",
            "epoch 24; iter: 0; batch classifier loss: 0.374875\n",
            "epoch 24; iter: 200; batch classifier loss: 0.320824\n",
            "epoch 25; iter: 0; batch classifier loss: 0.330363\n",
            "epoch 25; iter: 200; batch classifier loss: 0.286915\n",
            "epoch 26; iter: 0; batch classifier loss: 0.299047\n",
            "epoch 26; iter: 200; batch classifier loss: 0.345240\n",
            "epoch 27; iter: 0; batch classifier loss: 0.388721\n",
            "epoch 27; iter: 200; batch classifier loss: 0.342737\n",
            "epoch 28; iter: 0; batch classifier loss: 0.342795\n",
            "epoch 28; iter: 200; batch classifier loss: 0.323666\n",
            "epoch 29; iter: 0; batch classifier loss: 0.281663\n",
            "epoch 29; iter: 200; batch classifier loss: 0.373716\n",
            "epoch 30; iter: 0; batch classifier loss: 0.377820\n",
            "epoch 30; iter: 200; batch classifier loss: 0.407348\n",
            "epoch 31; iter: 0; batch classifier loss: 0.360970\n",
            "epoch 31; iter: 200; batch classifier loss: 0.344627\n",
            "epoch 32; iter: 0; batch classifier loss: 0.406914\n",
            "epoch 32; iter: 200; batch classifier loss: 0.331791\n",
            "epoch 33; iter: 0; batch classifier loss: 0.338670\n",
            "epoch 33; iter: 200; batch classifier loss: 0.424915\n",
            "epoch 34; iter: 0; batch classifier loss: 0.355414\n",
            "epoch 34; iter: 200; batch classifier loss: 0.365404\n",
            "epoch 35; iter: 0; batch classifier loss: 0.309421\n",
            "epoch 35; iter: 200; batch classifier loss: 0.386926\n",
            "epoch 36; iter: 0; batch classifier loss: 0.348892\n",
            "epoch 36; iter: 200; batch classifier loss: 0.405427\n",
            "epoch 37; iter: 0; batch classifier loss: 0.359917\n",
            "epoch 37; iter: 200; batch classifier loss: 0.472356\n",
            "epoch 38; iter: 0; batch classifier loss: 0.416154\n",
            "epoch 38; iter: 200; batch classifier loss: 0.381085\n",
            "epoch 39; iter: 0; batch classifier loss: 0.415177\n",
            "epoch 39; iter: 200; batch classifier loss: 0.376502\n",
            "epoch 40; iter: 0; batch classifier loss: 0.285569\n",
            "epoch 40; iter: 200; batch classifier loss: 0.303067\n",
            "epoch 41; iter: 0; batch classifier loss: 0.398363\n",
            "epoch 41; iter: 200; batch classifier loss: 0.328759\n",
            "epoch 42; iter: 0; batch classifier loss: 0.300006\n",
            "epoch 42; iter: 200; batch classifier loss: 0.328082\n",
            "epoch 43; iter: 0; batch classifier loss: 0.322968\n",
            "epoch 43; iter: 200; batch classifier loss: 0.355489\n",
            "epoch 44; iter: 0; batch classifier loss: 0.425116\n",
            "epoch 44; iter: 200; batch classifier loss: 0.466781\n",
            "epoch 45; iter: 0; batch classifier loss: 0.310957\n",
            "epoch 45; iter: 200; batch classifier loss: 0.349369\n",
            "epoch 46; iter: 0; batch classifier loss: 0.461963\n",
            "epoch 46; iter: 200; batch classifier loss: 0.335750\n",
            "epoch 47; iter: 0; batch classifier loss: 0.291077\n",
            "epoch 47; iter: 200; batch classifier loss: 0.379471\n",
            "epoch 48; iter: 0; batch classifier loss: 0.318663\n",
            "epoch 48; iter: 200; batch classifier loss: 0.328823\n",
            "epoch 49; iter: 0; batch classifier loss: 0.329195\n",
            "epoch 49; iter: 200; batch classifier loss: 0.378164\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<aif360.algorithms.inprocessing.adversarial_debiasing.AdversarialDebiasing at 0x7fb08f5cd520>"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the plain model to test data\n",
        "dataset_nodebiasing_train = plain_model.predict(dataset_orig_train)\n",
        "dataset_nodebiasing_test = plain_model.predict(dataset_orig_test)"
      ],
      "metadata": {
        "id": "tXHsO-U-10jC"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Metrics for the dataset from plain model (without debiasing)\n",
        "display(Markdown(\"#### Plain model - without debiasing - dataset metrics\"))\n",
        "metric_dataset_nodebiasing_train = BinaryLabelDatasetMetric(dataset_nodebiasing_train, \n",
        "                                             unprivileged_groups=unprivileged_groups,\n",
        "                                             privileged_groups=privileged_groups)\n",
        "\n",
        "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_nodebiasing_train.mean_difference())\n",
        "\n",
        "metric_dataset_nodebiasing_test = BinaryLabelDatasetMetric(dataset_nodebiasing_test, \n",
        "                                             unprivileged_groups=unprivileged_groups,\n",
        "                                             privileged_groups=privileged_groups)\n",
        "\n",
        "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_nodebiasing_test.mean_difference())\n",
        "\n",
        "display(Markdown(\"#### Plain model - without debiasing - classification metrics\"))\n",
        "classified_metric_nodebiasing_test = ClassificationMetric(dataset_orig_test, \n",
        "                                                 dataset_nodebiasing_test,\n",
        "                                                 unprivileged_groups=unprivileged_groups,\n",
        "                                                 privileged_groups=privileged_groups)\n",
        "print(\"Test set: Classification accuracy = %f\" % classified_metric_nodebiasing_test.accuracy())\n",
        "TPR = classified_metric_nodebiasing_test.true_positive_rate()\n",
        "TNR = classified_metric_nodebiasing_test.true_negative_rate()\n",
        "bal_acc_nodebiasing_test = 0.5*(TPR+TNR)\n",
        "print(\"Test set: Balanced classification accuracy = %f\" % bal_acc_nodebiasing_test)\n",
        "print(\"Test set: Disparate impact = %f\" % classified_metric_nodebiasing_test.disparate_impact())\n",
        "print(\"Test set: Equal opportunity difference = %f\" % classified_metric_nodebiasing_test.equal_opportunity_difference())\n",
        "print(\"Test set: Average odds difference = %f\" % classified_metric_nodebiasing_test.average_odds_difference())\n",
        "print(\"Test set: Theil_index = %f\" % classified_metric_nodebiasing_test.theil_index())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "WkzzZDqJ2ACZ",
        "outputId": "34b6b330-c8ff-41f6-f128-8b3f8365171c"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "#### Plain model - without debiasing - dataset metrics"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.196254\n",
            "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.211557\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "#### Plain model - without debiasing - classification metrics"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set: Classification accuracy = 0.829653\n",
            "Test set: Balanced classification accuracy = 0.749056\n",
            "Test set: Disparate impact = 0.256225\n",
            "Test set: Equal opportunity difference = -0.134901\n",
            "Test set: Average odds difference = -0.123683\n",
            "Test set: Theil_index = 0.130220\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sess.close()\n",
        "tf.reset_default_graph()\n",
        "sess = tf.Session()"
      ],
      "metadata": {
        "id": "tQZeHMD32FY1"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Learn parameters with debias set to True\n",
        "debiased_model = AdversarialDebiasing(privileged_groups = privileged_groups,\n",
        "                          unprivileged_groups = unprivileged_groups,\n",
        "                          scope_name='debiased_classifier',\n",
        "                          debias=True,\n",
        "                          sess=sess)"
      ],
      "metadata": {
        "id": "bqAuS90b2Qdi"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "debiased_model.fit(dataset_orig_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSFPkmRw2Tan",
        "outputId": "b4016a10-010f-4dd7-9ceb-0c8f52a956c6"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0; iter: 0; batch classifier loss: 0.662189; batch adversarial loss: 0.712484\n",
            "epoch 0; iter: 200; batch classifier loss: 0.437959; batch adversarial loss: 0.652443\n",
            "epoch 1; iter: 0; batch classifier loss: 0.433306; batch adversarial loss: 0.637163\n",
            "epoch 1; iter: 200; batch classifier loss: 0.356403; batch adversarial loss: 0.631682\n",
            "epoch 2; iter: 0; batch classifier loss: 0.341237; batch adversarial loss: 0.613343\n",
            "epoch 2; iter: 200; batch classifier loss: 0.372082; batch adversarial loss: 0.591473\n",
            "epoch 3; iter: 0; batch classifier loss: 0.402502; batch adversarial loss: 0.625704\n",
            "epoch 3; iter: 200; batch classifier loss: 0.459799; batch adversarial loss: 0.540499\n",
            "epoch 4; iter: 0; batch classifier loss: 0.365844; batch adversarial loss: 0.637815\n",
            "epoch 4; iter: 200; batch classifier loss: 0.450494; batch adversarial loss: 0.634311\n",
            "epoch 5; iter: 0; batch classifier loss: 0.298644; batch adversarial loss: 0.617533\n",
            "epoch 5; iter: 200; batch classifier loss: 0.372367; batch adversarial loss: 0.570641\n",
            "epoch 6; iter: 0; batch classifier loss: 0.378419; batch adversarial loss: 0.550278\n",
            "epoch 6; iter: 200; batch classifier loss: 0.335464; batch adversarial loss: 0.647050\n",
            "epoch 7; iter: 0; batch classifier loss: 0.413143; batch adversarial loss: 0.608379\n",
            "epoch 7; iter: 200; batch classifier loss: 0.408560; batch adversarial loss: 0.575252\n",
            "epoch 8; iter: 0; batch classifier loss: 0.449933; batch adversarial loss: 0.611935\n",
            "epoch 8; iter: 200; batch classifier loss: 0.444422; batch adversarial loss: 0.593633\n",
            "epoch 9; iter: 0; batch classifier loss: 0.373686; batch adversarial loss: 0.637406\n",
            "epoch 9; iter: 200; batch classifier loss: 0.526464; batch adversarial loss: 0.587508\n",
            "epoch 10; iter: 0; batch classifier loss: 0.409967; batch adversarial loss: 0.609440\n",
            "epoch 10; iter: 200; batch classifier loss: 0.350895; batch adversarial loss: 0.614543\n",
            "epoch 11; iter: 0; batch classifier loss: 0.391342; batch adversarial loss: 0.596154\n",
            "epoch 11; iter: 200; batch classifier loss: 0.337408; batch adversarial loss: 0.627807\n",
            "epoch 12; iter: 0; batch classifier loss: 0.385159; batch adversarial loss: 0.651184\n",
            "epoch 12; iter: 200; batch classifier loss: 0.298176; batch adversarial loss: 0.616154\n",
            "epoch 13; iter: 0; batch classifier loss: 0.472774; batch adversarial loss: 0.559135\n",
            "epoch 13; iter: 200; batch classifier loss: 0.414948; batch adversarial loss: 0.648744\n",
            "epoch 14; iter: 0; batch classifier loss: 0.395018; batch adversarial loss: 0.620971\n",
            "epoch 14; iter: 200; batch classifier loss: 0.327922; batch adversarial loss: 0.609248\n",
            "epoch 15; iter: 0; batch classifier loss: 0.378938; batch adversarial loss: 0.651085\n",
            "epoch 15; iter: 200; batch classifier loss: 0.405989; batch adversarial loss: 0.659053\n",
            "epoch 16; iter: 0; batch classifier loss: 0.347745; batch adversarial loss: 0.598898\n",
            "epoch 16; iter: 200; batch classifier loss: 0.374999; batch adversarial loss: 0.655712\n",
            "epoch 17; iter: 0; batch classifier loss: 0.455086; batch adversarial loss: 0.598810\n",
            "epoch 17; iter: 200; batch classifier loss: 0.389341; batch adversarial loss: 0.621443\n",
            "epoch 18; iter: 0; batch classifier loss: 0.318378; batch adversarial loss: 0.613009\n",
            "epoch 18; iter: 200; batch classifier loss: 0.461025; batch adversarial loss: 0.632321\n",
            "epoch 19; iter: 0; batch classifier loss: 0.389589; batch adversarial loss: 0.598886\n",
            "epoch 19; iter: 200; batch classifier loss: 0.428970; batch adversarial loss: 0.593136\n",
            "epoch 20; iter: 0; batch classifier loss: 0.494994; batch adversarial loss: 0.573910\n",
            "epoch 20; iter: 200; batch classifier loss: 0.280126; batch adversarial loss: 0.604330\n",
            "epoch 21; iter: 0; batch classifier loss: 0.424785; batch adversarial loss: 0.585204\n",
            "epoch 21; iter: 200; batch classifier loss: 0.371353; batch adversarial loss: 0.595267\n",
            "epoch 22; iter: 0; batch classifier loss: 0.449328; batch adversarial loss: 0.583962\n",
            "epoch 22; iter: 200; batch classifier loss: 0.310390; batch adversarial loss: 0.621029\n",
            "epoch 23; iter: 0; batch classifier loss: 0.416629; batch adversarial loss: 0.602575\n",
            "epoch 23; iter: 200; batch classifier loss: 0.329052; batch adversarial loss: 0.629838\n",
            "epoch 24; iter: 0; batch classifier loss: 0.355499; batch adversarial loss: 0.622177\n",
            "epoch 24; iter: 200; batch classifier loss: 0.437750; batch adversarial loss: 0.562640\n",
            "epoch 25; iter: 0; batch classifier loss: 0.309671; batch adversarial loss: 0.663040\n",
            "epoch 25; iter: 200; batch classifier loss: 0.411989; batch adversarial loss: 0.609387\n",
            "epoch 26; iter: 0; batch classifier loss: 0.439169; batch adversarial loss: 0.661354\n",
            "epoch 26; iter: 200; batch classifier loss: 0.336243; batch adversarial loss: 0.622322\n",
            "epoch 27; iter: 0; batch classifier loss: 0.350930; batch adversarial loss: 0.552210\n",
            "epoch 27; iter: 200; batch classifier loss: 0.367292; batch adversarial loss: 0.574209\n",
            "epoch 28; iter: 0; batch classifier loss: 0.412860; batch adversarial loss: 0.634322\n",
            "epoch 28; iter: 200; batch classifier loss: 0.372810; batch adversarial loss: 0.596025\n",
            "epoch 29; iter: 0; batch classifier loss: 0.344462; batch adversarial loss: 0.660322\n",
            "epoch 29; iter: 200; batch classifier loss: 0.361817; batch adversarial loss: 0.588734\n",
            "epoch 30; iter: 0; batch classifier loss: 0.390348; batch adversarial loss: 0.578058\n",
            "epoch 30; iter: 200; batch classifier loss: 0.414037; batch adversarial loss: 0.613504\n",
            "epoch 31; iter: 0; batch classifier loss: 0.367861; batch adversarial loss: 0.598116\n",
            "epoch 31; iter: 200; batch classifier loss: 0.416422; batch adversarial loss: 0.638567\n",
            "epoch 32; iter: 0; batch classifier loss: 0.385941; batch adversarial loss: 0.637144\n",
            "epoch 32; iter: 200; batch classifier loss: 0.433644; batch adversarial loss: 0.638869\n",
            "epoch 33; iter: 0; batch classifier loss: 0.280832; batch adversarial loss: 0.636425\n",
            "epoch 33; iter: 200; batch classifier loss: 0.461563; batch adversarial loss: 0.601408\n",
            "epoch 34; iter: 0; batch classifier loss: 0.432847; batch adversarial loss: 0.597287\n",
            "epoch 34; iter: 200; batch classifier loss: 0.439270; batch adversarial loss: 0.620396\n",
            "epoch 35; iter: 0; batch classifier loss: 0.414792; batch adversarial loss: 0.602970\n",
            "epoch 35; iter: 200; batch classifier loss: 0.314371; batch adversarial loss: 0.570027\n",
            "epoch 36; iter: 0; batch classifier loss: 0.399010; batch adversarial loss: 0.576340\n",
            "epoch 36; iter: 200; batch classifier loss: 0.322901; batch adversarial loss: 0.622550\n",
            "epoch 37; iter: 0; batch classifier loss: 0.409068; batch adversarial loss: 0.647404\n",
            "epoch 37; iter: 200; batch classifier loss: 0.365523; batch adversarial loss: 0.627407\n",
            "epoch 38; iter: 0; batch classifier loss: 0.378191; batch adversarial loss: 0.599607\n",
            "epoch 38; iter: 200; batch classifier loss: 0.349827; batch adversarial loss: 0.619985\n",
            "epoch 39; iter: 0; batch classifier loss: 0.293259; batch adversarial loss: 0.630938\n",
            "epoch 39; iter: 200; batch classifier loss: 0.382462; batch adversarial loss: 0.637718\n",
            "epoch 40; iter: 0; batch classifier loss: 0.377819; batch adversarial loss: 0.570016\n",
            "epoch 40; iter: 200; batch classifier loss: 0.458273; batch adversarial loss: 0.661872\n",
            "epoch 41; iter: 0; batch classifier loss: 0.348432; batch adversarial loss: 0.582446\n",
            "epoch 41; iter: 200; batch classifier loss: 0.422338; batch adversarial loss: 0.614988\n",
            "epoch 42; iter: 0; batch classifier loss: 0.386026; batch adversarial loss: 0.666925\n",
            "epoch 42; iter: 200; batch classifier loss: 0.397367; batch adversarial loss: 0.637576\n",
            "epoch 43; iter: 0; batch classifier loss: 0.323756; batch adversarial loss: 0.574821\n",
            "epoch 43; iter: 200; batch classifier loss: 0.374398; batch adversarial loss: 0.565235\n",
            "epoch 44; iter: 0; batch classifier loss: 0.436159; batch adversarial loss: 0.617350\n",
            "epoch 44; iter: 200; batch classifier loss: 0.405331; batch adversarial loss: 0.597772\n",
            "epoch 45; iter: 0; batch classifier loss: 0.364503; batch adversarial loss: 0.573897\n",
            "epoch 45; iter: 200; batch classifier loss: 0.325900; batch adversarial loss: 0.616198\n",
            "epoch 46; iter: 0; batch classifier loss: 0.389208; batch adversarial loss: 0.590597\n",
            "epoch 46; iter: 200; batch classifier loss: 0.362676; batch adversarial loss: 0.657857\n",
            "epoch 47; iter: 0; batch classifier loss: 0.371187; batch adversarial loss: 0.611756\n",
            "epoch 47; iter: 200; batch classifier loss: 0.293207; batch adversarial loss: 0.606566\n",
            "epoch 48; iter: 0; batch classifier loss: 0.390950; batch adversarial loss: 0.628745\n",
            "epoch 48; iter: 200; batch classifier loss: 0.562088; batch adversarial loss: 0.644474\n",
            "epoch 49; iter: 0; batch classifier loss: 0.455562; batch adversarial loss: 0.566430\n",
            "epoch 49; iter: 200; batch classifier loss: 0.463114; batch adversarial loss: 0.614306\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<aif360.algorithms.inprocessing.adversarial_debiasing.AdversarialDebiasing at 0x7fb08ed148e0>"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the plain model to test data\n",
        "dataset_debiasing_train = debiased_model.predict(dataset_orig_train)\n",
        "dataset_debiasing_test = debiased_model.predict(dataset_orig_test)"
      ],
      "metadata": {
        "id": "4M3CQrxA2VuL"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Metrics for the dataset from plain model (without debiasing)\n",
        "display(Markdown(\"#### Plain model - without debiasing - dataset metrics\"))\n",
        "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_nodebiasing_train.mean_difference())\n",
        "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_nodebiasing_test.mean_difference())\n",
        "\n",
        "# Metrics for the dataset from model with debiasing\n",
        "display(Markdown(\"#### Model - with debiasing - dataset metrics\"))\n",
        "metric_dataset_debiasing_train = BinaryLabelDatasetMetric(dataset_debiasing_train, \n",
        "                                             unprivileged_groups=unprivileged_groups,\n",
        "                                             privileged_groups=privileged_groups)\n",
        "\n",
        "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_debiasing_train.mean_difference())\n",
        "\n",
        "metric_dataset_debiasing_test = BinaryLabelDatasetMetric(dataset_debiasing_test, \n",
        "                                             unprivileged_groups=unprivileged_groups,\n",
        "                                             privileged_groups=privileged_groups)\n",
        "\n",
        "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_debiasing_test.mean_difference())\n",
        "\n",
        "\n",
        "\n",
        "display(Markdown(\"#### Plain model - without debiasing - classification metrics\"))\n",
        "print(\"Test set: Classification accuracy = %f\" % classified_metric_nodebiasing_test.accuracy())\n",
        "TPR = classified_metric_nodebiasing_test.true_positive_rate()\n",
        "TNR = classified_metric_nodebiasing_test.true_negative_rate()\n",
        "bal_acc_nodebiasing_test = 0.5*(TPR+TNR)\n",
        "print(\"Test set: Balanced classification accuracy = %f\" % bal_acc_nodebiasing_test)\n",
        "print(\"Test set: Disparate impact = %f\" % classified_metric_nodebiasing_test.disparate_impact())\n",
        "print(\"Test set: Equal opportunity difference = %f\" % classified_metric_nodebiasing_test.equal_opportunity_difference())\n",
        "print(\"Test set: Average odds difference = %f\" % classified_metric_nodebiasing_test.average_odds_difference())\n",
        "print(\"Test set: Theil_index = %f\" % classified_metric_nodebiasing_test.theil_index())\n",
        "\n",
        "\n",
        "\n",
        "display(Markdown(\"#### Model - with debiasing - classification metrics\"))\n",
        "classified_metric_debiasing_test = ClassificationMetric(dataset_orig_test, \n",
        "                                                 dataset_debiasing_test,\n",
        "                                                 unprivileged_groups=unprivileged_groups,\n",
        "                                                 privileged_groups=privileged_groups)\n",
        "print(\"Test set: Classification accuracy = %f\" % classified_metric_debiasing_test.accuracy())\n",
        "TPR = classified_metric_debiasing_test.true_positive_rate()\n",
        "TNR = classified_metric_debiasing_test.true_negative_rate()\n",
        "bal_acc_debiasing_test = 0.5*(TPR+TNR)\n",
        "print(\"Test set: Balanced classification accuracy = %f\" % bal_acc_debiasing_test)\n",
        "print(\"Test set: Disparate impact = %f\" % classified_metric_debiasing_test.disparate_impact())\n",
        "print(\"Test set: Equal opportunity difference = %f\" % classified_metric_debiasing_test.equal_opportunity_difference())\n",
        "print(\"Test set: Average odds difference = %f\" % classified_metric_debiasing_test.average_odds_difference())\n",
        "print(\"Test set: Theil_index = %f\" % classified_metric_debiasing_test.theil_index())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "noMpXh6r2s2b",
        "outputId": "8bf00ea3-8a1a-4526-d413-3aeac1f95a62"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "#### Plain model - without debiasing - dataset metrics"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.196254\n",
            "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.211557\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "#### Model - with debiasing - dataset metrics"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.059039\n",
            "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.072444\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "#### Plain model - without debiasing - classification metrics"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set: Classification accuracy = 0.829653\n",
            "Test set: Balanced classification accuracy = 0.749056\n",
            "Test set: Disparate impact = 0.256225\n",
            "Test set: Equal opportunity difference = -0.134901\n",
            "Test set: Average odds difference = -0.123683\n",
            "Test set: Theil_index = 0.130220\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "#### Model - with debiasing - classification metrics"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set: Classification accuracy = 0.818794\n",
            "Test set: Balanced classification accuracy = 0.701742\n",
            "Test set: Disparate impact = 0.622537\n",
            "Test set: Equal opportunity difference = 0.177425\n",
            "Test set: Average odds difference = 0.079974\n",
            "Test set: Theil_index = 0.157820\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "export_data = dataset_orig_test.convert_to_dataframe()"
      ],
      "metadata": {
        "id": "MfkGTOiu23ov"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = export_data[0].copy()"
      ],
      "metadata": {
        "id": "vD2bfelR52t4"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def onehot_to_label_encode(feature, df):\n",
        "  cols = [x  for x in df.columns if feature in x]\n",
        "  df.loc[:, feature] = df.loc[:, cols].values.argmax(axis=1)\n",
        "  df = df.drop(cols, axis=1)\n",
        "\n",
        "  return df"
      ],
      "metadata": {
        "id": "Rf2QN6w_8-h5"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = onehot_to_label_encode(\"workclass\", df)"
      ],
      "metadata": {
        "id": "zCQWvflR6N9s"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = onehot_to_label_encode(\"marital-status\", df)\n",
        "df = onehot_to_label_encode(\"Education\", df)"
      ],
      "metadata": {
        "id": "-b4UvUvC9nBV"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = onehot_to_label_encode(\"Age\", df)"
      ],
      "metadata": {
        "id": "I1tCc4jC94MW"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop([\"race\"], axis=1)"
      ],
      "metadata": {
        "id": "Ay-GPO289-RJ"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"adult.csv\",index=False)"
      ],
      "metadata": {
        "id": "JwM5NGNg9_Q4"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dir(dataset_debiasing_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPK8hT80-KvQ",
        "outputId": "1ffc4653-8011-4bfe-c2a7-53eae14f3378"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__abstractmethods__',\n",
              " '__class__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__slotnames__',\n",
              " '__slots__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_abc_impl',\n",
              " '_de_dummy_code_df',\n",
              " '_parse_feature_names',\n",
              " 'align_datasets',\n",
              " 'convert_to_dataframe',\n",
              " 'copy',\n",
              " 'export_dataset',\n",
              " 'favorable_label',\n",
              " 'feature_names',\n",
              " 'features',\n",
              " 'ignore_fields',\n",
              " 'import_dataset',\n",
              " 'instance_names',\n",
              " 'instance_weights',\n",
              " 'label_names',\n",
              " 'labels',\n",
              " 'metadata',\n",
              " 'privileged_protected_attributes',\n",
              " 'protected_attribute_names',\n",
              " 'protected_attributes',\n",
              " 'scores',\n",
              " 'split',\n",
              " 'subset',\n",
              " 'temporarily_ignore',\n",
              " 'unfavorable_label',\n",
              " 'unprivileged_protected_attributes',\n",
              " 'validate_dataset']"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(dataset_orig_test.labels == dataset_debiasing_test.labels).sum()/len(dataset_debiasing_test.labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jbPQBqKBGKn",
        "outputId": "4c72abb5-f8b5-45c8-8e5a-9f6597e245d5"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8187938898139434"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHpByJILCQMU",
        "outputId": "659c8720-2daf-4aea-f074-164b45ff16ca"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['sex', 'hours-per-week', 'Income Binary', 'workclass', 'marital-status',\n",
              "       'Education', 'Age'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(df.loc[:, \"Income Binary\"].values  == dataset_debiasing_test.labels.reshape((-1))).sum()/len(dataset_debiasing_test.labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKGBDGbACARz",
        "outputId": "de9ad7da-f2d9-440c-bae2-0a651d83dabd"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[:, \"Income Binary\"] = dataset_debiasing_test.labels.reshape((-1))"
      ],
      "metadata": {
        "id": "yttGvdcNCWK5"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"adult_adv_debias.csv\",index=False)"
      ],
      "metadata": {
        "id": "gnDDauF3CYTR"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E6yOb88TCuAQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}