{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gvtXBg6Hdm6g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "76739f35-0f32-4710-f511-1e86e5cc223c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting aif360[all]\n",
            "  Downloading aif360-0.5.0-py3-none-any.whl (214 kB)\n",
            "\u001b[K     |████████████████████████████████| 214 kB 7.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=1.0 in /usr/local/lib/python3.8/dist-packages (from aif360[all]) (1.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from aif360[all]) (3.2.2)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.8/dist-packages (from aif360[all]) (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.8/dist-packages (from aif360[all]) (1.21.6)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from aif360[all]) (1.7.3)\n",
            "Collecting BlackBoxAuditing\n",
            "  Downloading BlackBoxAuditing-0.1.54.tar.gz (2.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6 MB 6.4 MB/s \n",
            "\u001b[?25hCollecting igraph[plotting]\n",
            "  Downloading igraph-0.10.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 45.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lightgbm in /usr/local/lib/python3.8/dist-packages (from aif360[all]) (2.2.3)\n",
            "Collecting adversarial-robustness-toolbox>=1.0.0\n",
            "  Downloading adversarial_robustness_toolbox-1.12.2-py3-none-any.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 61.2 MB/s \n",
            "\u001b[?25hCollecting tempeh\n",
            "  Downloading tempeh-0.1.12-py3-none-any.whl (39 kB)\n",
            "Requirement already satisfied: pytest>=3.5 in /usr/local/lib/python3.8/dist-packages (from aif360[all]) (3.6.4)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.8/dist-packages (from aif360[all]) (0.11.2)\n",
            "Requirement already satisfied: cvxpy>=1.0 in /usr/local/lib/python3.8/dist-packages (from aif360[all]) (1.2.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from aif360[all]) (1.13.0+cu116)\n",
            "Collecting jupyter\n",
            "  Downloading jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\n",
            "Collecting ipympl\n",
            "  Downloading ipympl-0.9.2-py2.py3-none-any.whl (510 kB)\n",
            "\u001b[K     |████████████████████████████████| 510 kB 58.5 MB/s \n",
            "\u001b[?25hCollecting fairlearn~=0.7\n",
            "  Downloading fairlearn-0.8.0-py3-none-any.whl (235 kB)\n",
            "\u001b[K     |████████████████████████████████| 235 kB 62.6 MB/s \n",
            "\u001b[?25hCollecting lime\n",
            "  Downloading lime-0.2.0.1.tar.gz (275 kB)\n",
            "\u001b[K     |████████████████████████████████| 275 kB 57.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from aif360[all]) (4.64.1)\n",
            "Requirement already satisfied: rpy2 in /usr/local/lib/python3.8/dist-packages (from aif360[all]) (3.5.5)\n",
            "Requirement already satisfied: jinja2<3.1.0 in /usr/local/lib/python3.8/dist-packages (from aif360[all]) (2.11.3)\n",
            "Requirement already satisfied: tensorflow>=1.13.1 in /usr/local/lib/python3.8/dist-packages (from aif360[all]) (2.9.2)\n",
            "Requirement already satisfied: sphinx<2 in /usr/local/lib/python3.8/dist-packages (from aif360[all]) (1.8.6)\n",
            "Collecting sphinx-rtd-theme\n",
            "  Downloading sphinx_rtd_theme-1.1.1-py2.py3-none-any.whl (2.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.8 MB 53.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from adversarial-robustness-toolbox>=1.0.0->aif360[all]) (57.4.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from adversarial-robustness-toolbox>=1.0.0->aif360[all]) (1.15.0)\n",
            "Requirement already satisfied: osqp>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from cvxpy>=1.0->aif360[all]) (0.6.2.post0)\n",
            "Requirement already satisfied: scs>=1.1.6 in /usr/local/lib/python3.8/dist-packages (from cvxpy>=1.0->aif360[all]) (3.2.2)\n",
            "Requirement already satisfied: ecos>=2 in /usr/local/lib/python3.8/dist-packages (from cvxpy>=1.0->aif360[all]) (2.0.10)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2<3.1.0->aif360[all]) (2.0.1)\n",
            "Requirement already satisfied: qdldl in /usr/local/lib/python3.8/dist-packages (from osqp>=0.4.1->cvxpy>=1.0->aif360[all]) (0.1.5.post2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.24.0->aif360[all]) (2022.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.24.0->aif360[all]) (2.8.2)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from pytest>=3.5->aif360[all]) (9.0.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.8/dist-packages (from pytest>=3.5->aif360[all]) (22.1.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.8/dist-packages (from pytest>=3.5->aif360[all]) (0.7.1)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.8/dist-packages (from pytest>=3.5->aif360[all]) (1.4.1)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.8/dist-packages (from pytest>=3.5->aif360[all]) (1.11.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0->aif360[all]) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0->aif360[all]) (3.1.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from sphinx<2->aif360[all]) (2.23.0)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.8/dist-packages (from sphinx<2->aif360[all]) (2.2.0)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.8/dist-packages (from sphinx<2->aif360[all]) (0.7.12)\n",
            "Requirement already satisfied: docutils<0.18,>=0.11 in /usr/local/lib/python3.8/dist-packages (from sphinx<2->aif360[all]) (0.17.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from sphinx<2->aif360[all]) (21.3)\n",
            "Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.8/dist-packages (from sphinx<2->aif360[all]) (2.11.0)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.8/dist-packages (from sphinx<2->aif360[all]) (1.4.1)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.8/dist-packages (from sphinx<2->aif360[all]) (2.6.1)\n",
            "Requirement already satisfied: sphinxcontrib-websupport in /usr/local/lib/python3.8/dist-packages (from sphinx<2->aif360[all]) (1.2.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.0.0->sphinx<2->aif360[all]) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.0.0->sphinx<2->aif360[all]) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.0.0->sphinx<2->aif360[all]) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.0.0->sphinx<2->aif360[all]) (2022.12.7)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=1.13.1->aif360[all]) (1.6.3)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=1.13.1->aif360[all]) (14.0.6)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=1.13.1->aif360[all]) (3.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=1.13.1->aif360[all]) (1.14.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=1.13.1->aif360[all]) (1.51.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=1.13.1->aif360[all]) (1.1.2)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=1.13.1->aif360[all]) (2.9.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=1.13.1->aif360[all]) (1.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=1.13.1->aif360[all]) (4.4.0)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=1.13.1->aif360[all]) (2.9.1)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=1.13.1->aif360[all]) (3.19.6)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=1.13.1->aif360[all]) (2.9.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=1.13.1->aif360[all]) (2.1.1)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=1.13.1->aif360[all]) (1.12)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=1.13.1->aif360[all]) (3.3.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=1.13.1->aif360[all]) (0.2.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=1.13.1->aif360[all]) (0.4.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=1.13.1->aif360[all]) (0.28.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow>=1.13.1->aif360[all]) (0.38.4)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=1.13.1->aif360[all]) (2.15.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=1.13.1->aif360[all]) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=1.13.1->aif360[all]) (3.4.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=1.13.1->aif360[all]) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=1.13.1->aif360[all]) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=1.13.1->aif360[all]) (1.8.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>=1.13.1->aif360[all]) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>=1.13.1->aif360[all]) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>=1.13.1->aif360[all]) (5.2.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow>=1.13.1->aif360[all]) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow>=1.13.1->aif360[all]) (5.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow>=1.13.1->aif360[all]) (3.11.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>=1.13.1->aif360[all]) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow>=1.13.1->aif360[all]) (3.2.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.8/dist-packages (from BlackBoxAuditing->aif360[all]) (2.8.8)\n",
            "Collecting texttable>=1.6.2\n",
            "  Downloading texttable-1.6.7-py2.py3-none-any.whl (10 kB)\n",
            "Collecting cairocffi>=1.2.0\n",
            "  Downloading cairocffi-1.4.0.tar.gz (69 kB)\n",
            "\u001b[K     |████████████████████████████████| 69 kB 9.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from cairocffi>=1.2.0->igraph[plotting]->aif360[all]) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.1.0->cairocffi>=1.2.0->igraph[plotting]->aif360[all]) (2.21)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.8/dist-packages (from ipympl->aif360[all]) (0.2.0)\n",
            "Requirement already satisfied: traitlets<6 in /usr/local/lib/python3.8/dist-packages (from ipympl->aif360[all]) (5.7.1)\n",
            "Requirement already satisfied: ipywidgets<9,>=7.6.0 in /usr/local/lib/python3.8/dist-packages (from ipympl->aif360[all]) (7.7.1)\n",
            "Collecting matplotlib\n",
            "  Downloading matplotlib-3.6.2-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (9.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.4 MB 46.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: ipython<9 in /usr/local/lib/python3.8/dist-packages (from ipympl->aif360[all]) (7.9.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from ipympl->aif360[all]) (7.1.2)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 58.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython<9->ipympl->aif360[all]) (0.2.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython<9->ipympl->aif360[all]) (0.7.5)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from ipython<9->ipympl->aif360[all]) (4.8.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from ipython<9->ipympl->aif360[all]) (2.0.10)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from ipython<9->ipympl->aif360[all]) (4.4.2)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets<9,>=7.6.0->ipympl->aif360[all]) (3.0.4)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets<9,>=7.6.0->ipympl->aif360[all]) (3.6.1)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.8/dist-packages (from ipywidgets<9,>=7.6.0->ipympl->aif360[all]) (5.3.4)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.8/dist-packages (from ipykernel>=4.5.1->ipywidgets<9,>=7.6.0->ipympl->aif360[all]) (6.0.4)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.8/dist-packages (from ipykernel>=4.5.1->ipywidgets<9,>=7.6.0->ipympl->aif360[all]) (6.1.12)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.10->ipython<9->ipympl->aif360[all]) (0.8.3)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->aif360[all]) (3.0.9)\n",
            "Collecting contourpy>=1.0.1\n",
            "  Downloading contourpy-1.0.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (295 kB)\n",
            "\u001b[K     |████████████████████████████████| 295 kB 74.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->aif360[all]) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->aif360[all]) (0.11.0)\n",
            "Collecting fonttools>=4.22.0\n",
            "  Downloading fonttools-4.38.0-py3-none-any.whl (965 kB)\n",
            "\u001b[K     |████████████████████████████████| 965 kB 58.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython<9->ipympl->aif360[all]) (0.2.5)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.8/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl->aif360[all]) (5.7.16)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl->aif360[all]) (5.7.0)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl->aif360[all]) (0.13.3)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl->aif360[all]) (1.8.0)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl->aif360[all]) (0.15.0)\n",
            "Requirement already satisfied: nbconvert<6.0 in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl->aif360[all]) (5.6.1)\n",
            "Requirement already satisfied: jupyter-core>=4.4.0 in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl->aif360[all]) (5.1.0)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl->aif360[all]) (23.2.1)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.8/dist-packages (from jupyter-core>=4.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl->aif360[all]) (2.6.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl->aif360[all]) (1.5.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.8/dist-packages (from nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl->aif360[all]) (5.0.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.8/dist-packages (from nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl->aif360[all]) (0.4)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.8/dist-packages (from nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl->aif360[all]) (0.8.4)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.8/dist-packages (from nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl->aif360[all]) (0.6.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.8/dist-packages (from nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl->aif360[all]) (0.7.1)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.8/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl->aif360[all]) (2.16.2)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.8/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl->aif360[all]) (4.3.3)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl->aif360[all]) (5.10.1)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl->aif360[all]) (0.19.2)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.8/dist-packages (from terminado>=0.8.1->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl->aif360[all]) (0.7.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.8/dist-packages (from bleach->nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl->aif360[all]) (0.5.1)\n",
            "Collecting qtconsole\n",
            "  Downloading qtconsole-5.4.0-py3-none-any.whl (121 kB)\n",
            "\u001b[K     |████████████████████████████████| 121 kB 47.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jupyter-console in /usr/local/lib/python3.8/dist-packages (from jupyter->aif360[all]) (6.1.0)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.8/dist-packages (from lime->aif360[all]) (0.18.3)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.12->lime->aif360[all]) (2.9.0)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.12->lime->aif360[all]) (2022.10.10)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.12->lime->aif360[all]) (1.4.1)\n",
            "Collecting qtpy>=2.0.1\n",
            "  Downloading QtPy-2.3.0-py3-none-any.whl (83 kB)\n",
            "\u001b[K     |████████████████████████████████| 83 kB 2.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tzlocal in /usr/local/lib/python3.8/dist-packages (from rpy2->aif360[all]) (1.5.1)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml in /usr/local/lib/python3.8/dist-packages (from sphinxcontrib-websupport->sphinx<2->aif360[all]) (1.1.5)\n",
            "Collecting memory-profiler\n",
            "  Downloading memory_profiler-0.61.0-py3-none-any.whl (31 kB)\n",
            "Collecting shap\n",
            "  Downloading shap-0.41.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (575 kB)\n",
            "\u001b[K     |████████████████████████████████| 575 kB 47.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from memory-profiler->tempeh->aif360[all]) (5.4.8)\n",
            "Collecting slicer==0.0.7\n",
            "  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.8/dist-packages (from shap->tempeh->aif360[all]) (1.5.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.8/dist-packages (from shap->tempeh->aif360[all]) (0.56.4)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.8/dist-packages (from numba->shap->tempeh->aif360[all]) (0.39.1)\n",
            "Building wheels for collected packages: BlackBoxAuditing, cairocffi, lime\n",
            "  Building wheel for BlackBoxAuditing (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for BlackBoxAuditing: filename=BlackBoxAuditing-0.1.54-py2.py3-none-any.whl size=1394770 sha256=559bef78bbaa92cc0784aed5d125ce391fe204043d286306f91f4b270975edbf\n",
            "  Stored in directory: /root/.cache/pip/wheels/e3/77/36/a32ec1b04c2ebe2c45e88d42f33f22f987e76aad3f297b681e\n",
            "  Building wheel for cairocffi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cairocffi: filename=cairocffi-1.4.0-py3-none-any.whl size=88775 sha256=4f5f671325250c883850eb483ec6477ca7fe125b049591538eb46025d2a618a7\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/a9/c0/5c05f9dd73c21f9a7716690642823cdba55594d17a9bd69daf\n",
            "  Building wheel for lime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lime: filename=lime-0.2.0.1-py3-none-any.whl size=283857 sha256=8695e12c97db84f4b5274853a8d03f949ab97227e67c258e5c388511ac0c6113\n",
            "  Stored in directory: /root/.cache/pip/wheels/e6/a6/20/cc1e293fcdb67ede666fed293cb895395e7ecceb4467779546\n",
            "Successfully built BlackBoxAuditing cairocffi lime\n",
            "Installing collected packages: jedi, fonttools, contourpy, texttable, slicer, qtpy, matplotlib, shap, qtconsole, memory-profiler, igraph, cairocffi, tempeh, sphinx-rtd-theme, lime, jupyter, ipympl, fairlearn, BlackBoxAuditing, aif360, adversarial-robustness-toolbox\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "Successfully installed BlackBoxAuditing-0.1.54 adversarial-robustness-toolbox-1.12.2 aif360-0.5.0 cairocffi-1.4.0 contourpy-1.0.6 fairlearn-0.8.0 fonttools-4.38.0 igraph-0.10.2 ipympl-0.9.2 jedi-0.18.2 jupyter-1.0.0 lime-0.2.0.1 matplotlib-3.6.2 memory-profiler-0.61.0 qtconsole-5.4.0 qtpy-2.3.0 shap-0.41.0 slicer-0.0.7 sphinx-rtd-theme-1.1.1 tempeh-0.1.12 texttable-1.6.7\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install 'aif360[all]'  "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cp adult* /usr/local/lib/python3.8/dist-packages/aif360/data/raw/adult/."
      ],
      "metadata": {
        "id": "hm8Yh9fxeUdj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "# Load all necessary packages\n",
        "import sys\n",
        "sys.path.append(\"../\")\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "from aif360.datasets import BinaryLabelDataset\n",
        "from aif360.datasets import AdultDataset, GermanDataset, CompasDataset\n",
        "from aif360.metrics import BinaryLabelDatasetMetric\n",
        "from aif360.metrics import ClassificationMetric\n",
        "from aif360.algorithms.preprocessing.reweighing import Reweighing\n",
        "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions\\\n",
        "        import load_preproc_data_adult, load_preproc_data_german, load_preproc_data_compas\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from IPython.display import Markdown, display\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "X6_3JtB-d4K9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Metrics function\n",
        "from collections import OrderedDict\n",
        "from aif360.metrics import ClassificationMetric\n",
        "\n",
        "def compute_metrics(dataset_true, dataset_pred, \n",
        "                    unprivileged_groups, privileged_groups,\n",
        "                    disp = True):\n",
        "    \"\"\" Compute the key metrics \"\"\"\n",
        "    classified_metric_pred = ClassificationMetric(dataset_true,\n",
        "                                                 dataset_pred, \n",
        "                                                 unprivileged_groups=unprivileged_groups,\n",
        "                                                 privileged_groups=privileged_groups)\n",
        "    metrics = OrderedDict()\n",
        "    metrics[\"Balanced accuracy\"] = 0.5*(classified_metric_pred.true_positive_rate()+\n",
        "                                             classified_metric_pred.true_negative_rate())\n",
        "    metrics[\"Statistical parity difference\"] = classified_metric_pred.statistical_parity_difference()\n",
        "    metrics[\"Disparate impact\"] = classified_metric_pred.disparate_impact()\n",
        "    metrics[\"Average odds difference\"] = classified_metric_pred.average_odds_difference()\n",
        "    metrics[\"Equal opportunity difference\"] = classified_metric_pred.equal_opportunity_difference()\n",
        "    metrics[\"Theil index\"] = classified_metric_pred.theil_index()\n",
        "    \n",
        "    if disp:\n",
        "        for k in metrics:\n",
        "            print(\"%s = %.4f\" % (k, metrics[k]))\n",
        "    \n",
        "    return metrics"
      ],
      "metadata": {
        "id": "0ei6S9ISfjNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from aif360.datasets import AdultDataset, GermanDataset, CompasDataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def load_preproc_data_adult(protected_attributes=None, sub_samp=False, balance=False):\n",
        "    def custom_preprocessing(df):\n",
        "        \"\"\"The custom pre-processing function is adapted from\n",
        "            https://github.com/fair-preprocessing/nips2017/blob/master/Adult/code/Generate_Adult_Data.ipynb\n",
        "            If sub_samp != False, then return smaller version of dataset truncated to tiny_test data points.\n",
        "        \"\"\"\n",
        "\n",
        "        # Group age by decade\n",
        "        df['Age (decade)'] = df['age'].apply(lambda x: x//10*10)\n",
        "        # df['Age (decade)'] = df['age'].apply(lambda x: np.floor(x/10.0)*10.0)\n",
        "\n",
        "        def group_edu(x):\n",
        "            if x <= 5:\n",
        "                return '<6'\n",
        "            elif x >= 13:\n",
        "                return '>12'\n",
        "            else:\n",
        "                return x\n",
        "\n",
        "        def age_cut(x):\n",
        "            if x >= 70:\n",
        "                return '>=70'\n",
        "            else:\n",
        "                return x\n",
        "\n",
        "        def group_race(x):\n",
        "            if x == \"White\":\n",
        "                return 1.0\n",
        "            else:\n",
        "                return 0.0\n",
        "\n",
        "        # Cluster education and age attributes.\n",
        "        # Limit education range\n",
        "        df['Education Years'] = df['education-num'].apply(lambda x: group_edu(x))\n",
        "        df['Education Years'] = df['Education Years'].astype('category')\n",
        "\n",
        "        # Limit age range\n",
        "        df['Age (decade)'] = df['Age (decade)'].apply(lambda x: age_cut(x))\n",
        "\n",
        "        # Rename income variable\n",
        "        df['Income Binary'] = df['income-per-year']\n",
        "        df['Income Binary'] = df['Income Binary'].replace(to_replace='>50K.', value='>50K', regex=True)\n",
        "        df['Income Binary'] = df['Income Binary'].replace(to_replace='<=50K.', value='<=50K', regex=True)\n",
        "\n",
        "        # Recode sex and race\n",
        "        df['sex'] = df['sex'].replace({'Female': 0.0, 'Male': 1.0})\n",
        "        df['race'] = df['race'].apply(lambda x: group_race(x))\n",
        "\n",
        "        if sub_samp and not balance:\n",
        "            df = df.sample(sub_samp)\n",
        "        if sub_samp and balance:\n",
        "            df_0 = df[df['Income Binary'] == '<=50K']\n",
        "            df_1 = df[df['Income Binary'] == '>50K']\n",
        "            df_0 = df_0.sample(int(sub_samp/2))\n",
        "            df_1 = df_1.sample(int(sub_samp/2))\n",
        "            df = pd.concat([df_0, df_1])\n",
        "        return df\n",
        "\n",
        "    XD_features = ['Age (decade)', 'Education Years', 'hours-per-week', 'sex', 'race']\n",
        "    D_features = ['sex', 'race'] if protected_attributes is None else protected_attributes\n",
        "    Y_features = ['Income Binary']\n",
        "    X_features = list(set(XD_features)-set(D_features))\n",
        "    categorical_features = ['Age (decade)', 'Education Years', 'marital-status', 'workclass']\n",
        "\n",
        "    # privileged classes\n",
        "    all_privileged_classes = {\"sex\": [1.0],\n",
        "                              \"race\": [1.0]}\n",
        "\n",
        "    # protected attribute maps\n",
        "    all_protected_attribute_maps = {\"sex\": {1.0: 'Male', 0.0: 'Female'},\n",
        "                                    \"race\": {1.0: 'White', 0.0: 'Non-white'}}\n",
        "\n",
        "    return AdultDataset(\n",
        "        label_name=Y_features[0],\n",
        "        favorable_classes=['>50K', '>50K.'],\n",
        "        protected_attribute_names=D_features,\n",
        "        privileged_classes=[all_privileged_classes[x] for x in D_features],\n",
        "        instance_weights_name=None,\n",
        "        categorical_features=categorical_features,\n",
        "        features_to_keep=X_features+Y_features+D_features,\n",
        "        na_values=['?'],\n",
        "        metadata={'label_maps': [{1.0: '>50K', 0.0: '<=50K'}],\n",
        "                  'protected_attribute_maps': [all_protected_attribute_maps[x]\n",
        "                                for x in D_features]},\n",
        "        custom_preprocessing=custom_preprocessing)"
      ],
      "metadata": {
        "id": "niqVAFWzfq3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the dataset and split into train and test\n",
        "dataset_orig = load_preproc_data_adult()\n",
        "\n",
        "privileged_groups = [{'sex': 1}]\n",
        "unprivileged_groups = [{'sex': 0}]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JyUsku26eGak",
        "outputId": "8d66bed9-8cf6-4a9a-d618-1b6ae2d50dc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Missing Data: 2799 rows removed from AdultDataset.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the dataset and split into train and test\n",
        "dataset_orig_train, dataset_orig_vt = dataset_orig.split([0.7], shuffle=True)\n",
        "dataset_orig_valid, dataset_orig_test = dataset_orig_vt.split([0.5], shuffle=True)"
      ],
      "metadata": {
        "id": "ySbVPw9ceM-f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print out some labels, names, etc.\n",
        "display(Markdown(\"#### Training Dataset shape\"))\n",
        "print(dataset_orig_train.features.shape)\n",
        "display(Markdown(\"#### Favorable and unfavorable labels\"))\n",
        "print(dataset_orig_train.favorable_label, dataset_orig_train.unfavorable_label)\n",
        "display(Markdown(\"#### Protected attribute names\"))\n",
        "print(dataset_orig_train.protected_attribute_names)\n",
        "display(Markdown(\"#### Privileged and unprivileged protected attribute values\"))\n",
        "print(dataset_orig_train.privileged_protected_attributes, \n",
        "      dataset_orig_train.unprivileged_protected_attributes)\n",
        "display(Markdown(\"#### Dataset feature names\"))\n",
        "print(dataset_orig_train.feature_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "HBYnuBNUeOHP",
        "outputId": "30d991d7-737c-460b-d787-e9988d86694f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "#### Training Dataset shape"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32230, 34)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "#### Favorable and unfavorable labels"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0 0.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "#### Protected attribute names"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['sex', 'race']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "#### Privileged and unprivileged protected attribute values"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([1.]), array([1.])] [array([0.]), array([0.])]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "#### Dataset feature names"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['race', 'sex', 'hours-per-week', 'workclass=Federal-gov', 'workclass=Local-gov', 'workclass=Never-worked', 'workclass=Private', 'workclass=Self-emp-inc', 'workclass=Self-emp-not-inc', 'workclass=State-gov', 'workclass=Without-pay', 'marital-status=Divorced', 'marital-status=Married-AF-spouse', 'marital-status=Married-civ-spouse', 'marital-status=Married-spouse-absent', 'marital-status=Never-married', 'marital-status=Separated', 'marital-status=Widowed', 'Age (decade)=10', 'Age (decade)=20', 'Age (decade)=30', 'Age (decade)=40', 'Age (decade)=50', 'Age (decade)=60', 'Age (decade)=>=70', 'Education Years=6', 'Education Years=7', 'Education Years=8', 'Education Years=9', 'Education Years=10', 'Education Years=11', 'Education Years=12', 'Education Years=<6', 'Education Years=>12']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metric_orig_train = BinaryLabelDatasetMetric(dataset_orig_train, \n",
        "                                             unprivileged_groups=unprivileged_groups,\n",
        "                                             privileged_groups=privileged_groups)\n",
        "display(Markdown(\"#### Original training dataset\"))\n",
        "print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_train.mean_difference())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "pE4eMcKKeOYo",
        "outputId": "8fa01c49-4967-4aac-9137-400d41ea11c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "#### Original training dataset"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Difference in mean outcomes between unprivileged and privileged groups = -0.202056\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "RW = Reweighing(unprivileged_groups=unprivileged_groups,\n",
        "               privileged_groups=privileged_groups)\n",
        "RW.fit(dataset_orig_train)\n",
        "dataset_transf_train = RW.transform(dataset_orig_train)"
      ],
      "metadata": {
        "id": "DtTvltUqgJco"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert np.abs(dataset_transf_train.instance_weights.sum()-dataset_orig_train.instance_weights.sum())<1e-6"
      ],
      "metadata": {
        "id": "YxUeOQScgO-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metric_transf_train = BinaryLabelDatasetMetric(dataset_transf_train, \n",
        "                                         unprivileged_groups=unprivileged_groups,\n",
        "                                         privileged_groups=privileged_groups)\n",
        "display(Markdown(\"#### Transformed training dataset\"))\n",
        "print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_transf_train.mean_difference())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "LWkqrAPqgSmr",
        "outputId": "e7967cbc-43f0-403e-c39c-c129a708320c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "#### Transformed training dataset"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Difference in mean outcomes between unprivileged and privileged groups = 0.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic regression classifier and predictions\n",
        "scale_orig = StandardScaler()\n",
        "X_train = scale_orig.fit_transform(dataset_orig_train.features)\n",
        "y_train = dataset_orig_train.labels.ravel()\n",
        "w_train = dataset_orig_train.instance_weights.ravel()\n",
        "\n",
        "lmod = LogisticRegression()\n",
        "lmod.fit(X_train, y_train, \n",
        "         sample_weight=dataset_orig_train.instance_weights)\n",
        "y_train_pred = lmod.predict(X_train)\n",
        "\n",
        "# positive class index\n",
        "pos_ind = np.where(lmod.classes_ == dataset_orig_train.favorable_label)[0][0]\n",
        "\n",
        "dataset_orig_train_pred = dataset_orig_train.copy()\n",
        "dataset_orig_train_pred.labels = y_train_pred"
      ],
      "metadata": {
        "id": "TP69KXEUgXN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_orig_valid_pred = dataset_orig_valid.copy(deepcopy=True)\n",
        "X_valid = scale_orig.transform(dataset_orig_valid_pred.features)\n",
        "y_valid = dataset_orig_valid_pred.labels\n",
        "dataset_orig_valid_pred.scores = lmod.predict_proba(X_valid)[:,pos_ind].reshape(-1,1)\n",
        "\n",
        "dataset_orig_test_pred = dataset_orig_test.copy(deepcopy=True)\n",
        "X_test = scale_orig.transform(dataset_orig_test_pred.features)\n",
        "y_test = dataset_orig_test_pred.labels\n",
        "dataset_orig_test_pred.scores = lmod.predict_proba(X_test)[:,pos_ind].reshape(-1,1)"
      ],
      "metadata": {
        "id": "N_4bvAUfgdh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_thresh = 100\n",
        "ba_arr = np.zeros(num_thresh)\n",
        "class_thresh_arr = np.linspace(0.01, 0.99, num_thresh)\n",
        "for idx, class_thresh in enumerate(class_thresh_arr):\n",
        "    \n",
        "    fav_inds = dataset_orig_valid_pred.scores > class_thresh\n",
        "    dataset_orig_valid_pred.labels[fav_inds] = dataset_orig_valid_pred.favorable_label\n",
        "    dataset_orig_valid_pred.labels[~fav_inds] = dataset_orig_valid_pred.unfavorable_label\n",
        "    \n",
        "    classified_metric_orig_valid = ClassificationMetric(dataset_orig_valid,\n",
        "                                             dataset_orig_valid_pred, \n",
        "                                             unprivileged_groups=unprivileged_groups,\n",
        "                                             privileged_groups=privileged_groups)\n",
        "    \n",
        "    ba_arr[idx] = 0.5*(classified_metric_orig_valid.true_positive_rate()\\\n",
        "                       +classified_metric_orig_valid.true_negative_rate())\n",
        "\n",
        "best_ind = np.where(ba_arr == np.max(ba_arr))[0][0]\n",
        "best_class_thresh = class_thresh_arr[best_ind]\n",
        "\n",
        "print(\"Best balanced accuracy (no reweighing) = %.4f\" % np.max(ba_arr))\n",
        "print(\"Optimal classification threshold (no reweighing) = %.4f\" % best_class_thresh)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcOmpG7EghVu",
        "outputId": "2a494798-394c-449b-b60d-c6910c68ee3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best balanced accuracy (no reweighing) = 0.8048\n",
            "Optimal classification threshold (no reweighing) = 0.2377\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(Markdown(\"#### Predictions from original testing data\"))\n",
        "bal_acc_arr_orig = []\n",
        "disp_imp_arr_orig = []\n",
        "avg_odds_diff_arr_orig = []\n",
        "\n",
        "print(\"Classification threshold used = %.4f\" % best_class_thresh)\n",
        "for thresh in tqdm(class_thresh_arr):\n",
        "    \n",
        "    if thresh == best_class_thresh:\n",
        "        disp = True\n",
        "    else:\n",
        "        disp = False\n",
        "    \n",
        "    fav_inds = dataset_orig_test_pred.scores > thresh\n",
        "    dataset_orig_test_pred.labels[fav_inds] = dataset_orig_test_pred.favorable_label\n",
        "    dataset_orig_test_pred.labels[~fav_inds] = dataset_orig_test_pred.unfavorable_label\n",
        "    \n",
        "    metric_test_bef = compute_metrics(dataset_orig_test, dataset_orig_test_pred, \n",
        "                                      unprivileged_groups, privileged_groups,\n",
        "                                      disp = disp)\n",
        "\n",
        "    bal_acc_arr_orig.append(metric_test_bef[\"Balanced accuracy\"])\n",
        "    avg_odds_diff_arr_orig.append(metric_test_bef[\"Average odds difference\"])\n",
        "    disp_imp_arr_orig.append(metric_test_bef[\"Disparate impact\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "id": "7QbEXpmYgm5q",
        "outputId": "0bf694ae-b396-4a9d-ae74-b66c6c31ff12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "#### Predictions from original testing data"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification threshold used = 0.2377\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|███       | 30/100 [00:00<00:01, 50.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Balanced accuracy = 0.7884\n",
            "Statistical parity difference = -0.3541\n",
            "Disparate impact = 0.3087\n",
            "Average odds difference = -0.2203\n",
            "Equal opportunity difference = -0.1628\n",
            "Theil index = 0.0913\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 95%|█████████▌| 95/100 [00:01<00:00, 44.29it/s]invalid value encountered in double_scalars\n",
            "100%|██████████| 100/100 [00:02<00:00, 49.01it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scale_transf = StandardScaler()\n",
        "X_train = scale_transf.fit_transform(dataset_transf_train.features)\n",
        "y_train = dataset_transf_train.labels.ravel()\n",
        "\n",
        "lmod = LogisticRegression()\n",
        "lmod.fit(X_train, y_train,\n",
        "        sample_weight=dataset_transf_train.instance_weights)\n",
        "y_train_pred = lmod.predict(X_train)"
      ],
      "metadata": {
        "id": "ZT3_2PQOgp9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_transf_test_pred = dataset_orig_test.copy(deepcopy=True)\n",
        "X_test = scale_transf.fit_transform(dataset_transf_test_pred.features)\n",
        "y_test = dataset_transf_test_pred.labels\n",
        "dataset_transf_test_pred.scores = lmod.predict_proba(X_test)[:,pos_ind].reshape(-1,1)"
      ],
      "metadata": {
        "id": "wU-HXFTmg0hD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(Markdown(\"#### Predictions from transformed testing data\"))\n",
        "bal_acc_arr_transf = []\n",
        "disp_imp_arr_transf = []\n",
        "avg_odds_diff_arr_transf = []\n",
        "\n",
        "print(\"Classification threshold used = %.4f\" % best_class_thresh)\n",
        "for thresh in tqdm(class_thresh_arr):\n",
        "    \n",
        "    if thresh == best_class_thresh:\n",
        "        disp = True\n",
        "    else:\n",
        "        disp = False\n",
        "    \n",
        "    fav_inds = dataset_transf_test_pred.scores > thresh\n",
        "    dataset_transf_test_pred.labels[fav_inds] = dataset_transf_test_pred.favorable_label\n",
        "    dataset_transf_test_pred.labels[~fav_inds] = dataset_transf_test_pred.unfavorable_label\n",
        "    \n",
        "    metric_test_aft = compute_metrics(dataset_orig_test, dataset_transf_test_pred, \n",
        "                                      unprivileged_groups, privileged_groups,\n",
        "                                      disp = disp)\n",
        "\n",
        "    bal_acc_arr_transf.append(metric_test_aft[\"Balanced accuracy\"])\n",
        "    avg_odds_diff_arr_transf.append(metric_test_aft[\"Average odds difference\"])\n",
        "    disp_imp_arr_transf.append(metric_test_aft[\"Disparate impact\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "id": "mbiWOyDAhUJF",
        "outputId": "0efed88d-4be0-4b92-eeee-2a49dea068b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "#### Predictions from transformed testing data"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification threshold used = 0.2377\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 37%|███▋      | 37/100 [00:00<00:00, 69.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Balanced accuracy = 0.7705\n",
            "Statistical parity difference = -0.1702\n",
            "Disparate impact = 0.6153\n",
            "Average odds difference = -0.0160\n",
            "Equal opportunity difference = 0.0704\n",
            "Theil index = 0.1011\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 92%|█████████▏| 92/100 [00:01<00:00, 32.32it/s]divide by zero encountered in double_scalars\n",
            " 96%|█████████▌| 96/100 [00:02<00:00, 31.84it/s]invalid value encountered in double_scalars\n",
            "100%|██████████| 100/100 [00:02<00:00, 46.37it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(dataset_transf_test_pred.scores > best_class_thresh).reshape((-1)).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yg1sZxkzhdsV",
        "outputId": "e1ed7c90-e815-42a5-ac98-34a6ded4f358"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6907,)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "export_data = dataset_orig_test.convert_to_dataframe()"
      ],
      "metadata": {
        "id": "E0lwF-jQhhGh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = export_data[0].copy()"
      ],
      "metadata": {
        "id": "LdVseDkYh9LO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def onehot_to_label_encode(feature, df):\n",
        "  cols = [x  for x in df.columns if feature in x]\n",
        "  df.loc[:, feature] = df.loc[:, cols].values.argmax(axis=1)\n",
        "  df = df.drop(cols, axis=1)\n",
        "\n",
        "  return df"
      ],
      "metadata": {
        "id": "k5xj-rLKh_PO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = onehot_to_label_encode(\"workclass\", df)"
      ],
      "metadata": {
        "id": "p0iyt2GriGmn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = onehot_to_label_encode(\"marital-status\", df)\n",
        "df = onehot_to_label_encode(\"Education\", df)"
      ],
      "metadata": {
        "id": "3KnfCKJ1iPOR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = onehot_to_label_encode(\"Age\", df)"
      ],
      "metadata": {
        "id": "6WBoxIDziRaw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop([\"race\"], axis=1)"
      ],
      "metadata": {
        "id": "kkK1XHZ-iTcR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"adult_reweight.csv\",index=False)"
      ],
      "metadata": {
        "id": "RRKSmS3PiVQT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.rename(columns={\"hours-per-week\":\"hour\", \"Income Binary\":\"INCOME\", \"marital-status\":\"marital\"})"
      ],
      "metadata": {
        "id": "GpT0_vAciq8N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "marital-statussex,hours-per-week,Income Binary,workclass,marital-status,Education,Age"
      ],
      "metadata": {
        "id": "X_ftFaBAips7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sex,hours,INCOME,workclass,marital,Education,Age"
      ],
      "metadata": {
        "id": "Eyagp3hOiXx_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}